{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norovirus Receptor Discovery: Results Analysis\n",
    "\n",
    "This notebook demonstrates how to analyze results from the receptor discovery pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Define paths\n",
    "RESULTS_DIR = Path(\"../results\")\n",
    "DATA_DIR = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ranked candidates\n",
    "with open(RESULTS_DIR / \"ranked_candidates.json\") as f:\n",
    "    candidates = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(candidates)\n",
    "\n",
    "print(f\"Total candidates: {len(df)}\")\n",
    "print(f\"High confidence: {(df['confidence_tier'] == 'high').sum()}\")\n",
    "print(f\"Medium confidence: {(df['confidence_tier'] == 'medium').sum()}\")\n",
    "print(f\"Low confidence: {(df['confidence_tier'] == 'low').sum()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Top Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 20 candidates\n",
    "top_20 = df.head(20)[[\n",
    "    'rank', 'gene_name', 'protein_id', \n",
    "    'overall_score', 'ipTM_score', \n",
    "    'structural_confidence', 'biological_relevance',\n",
    "    'confidence_tier'\n",
    "]]\n",
    "\n",
    "top_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. High Confidence Candidates (ipTM > 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for high ipTM\n",
    "high_iptm = df[df['ipTM_score'] > 0.8].sort_values('overall_score', ascending=False)\n",
    "\n",
    "print(f\"\\nCandidates with ipTM > 0.8: {len(high_iptm)}\\n\")\n",
    "\n",
    "if len(high_iptm) > 0:\n",
    "    for idx, row in high_iptm.head(10).iterrows():\n",
    "        print(f\"{row['rank']}. {row['gene_name']} ({row['protein_id']})\")\n",
    "        print(f\"   Overall Score: {row['overall_score']:.3f}\")\n",
    "        print(f\"   ipTM: {row['ipTM_score']:.3f}\")\n",
    "        print(f\"   Interface pLDDT: {row['interface_pLDDT_score']*100:.1f}\")\n",
    "        print(f\"   Structural: {row['structural_confidence']:.3f}\")\n",
    "        print(f\"   Biological: {row['biological_relevance']:.3f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Score Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Overall score\n",
    "axes[0, 0].hist(df['overall_score'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(df['overall_score'].median(), color='red', linestyle='--', label='Median')\n",
    "axes[0, 0].set_xlabel('Overall Score')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('Overall Score Distribution')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# ipTM score\n",
    "axes[0, 1].hist(df['ipTM_score'], bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0, 1].axvline(df['ipTM_score'].median(), color='red', linestyle='--', label='Median')\n",
    "axes[0, 1].axvline(0.8, color='blue', linestyle='--', label='High threshold')\n",
    "axes[0, 1].set_xlabel('ipTM Score')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].set_title('ipTM Score Distribution')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Structural confidence\n",
    "axes[1, 0].hist(df['structural_confidence'], bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1, 0].set_xlabel('Structural Confidence')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Structural Confidence Distribution')\n",
    "\n",
    "# Biological relevance\n",
    "axes[1, 1].hist(df['biological_relevance'], bins=30, edgecolor='black', alpha=0.7, color='purple')\n",
    "axes[1, 1].set_xlabel('Biological Relevance')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].set_title('Biological Relevance Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'score_distributions.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "score_cols = [\n",
    "    'ipTM_score', 'interface_pLDDT_score', 'interface_area_score',\n",
    "    'interaction_score', 'geometry_score', 'consistency_score',\n",
    "    'expression_score', 'localization_score',\n",
    "    'structural_confidence', 'biological_relevance', 'overall_score'\n",
    "]\n",
    "\n",
    "corr = df[score_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Score Correlation Matrix', fontsize=14, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'score_correlations.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confidence Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of confidence tiers\n",
    "tier_counts = df['confidence_tier'].value_counts()\n",
    "\n",
    "colors = {'high': '#2ecc71', 'medium': '#f39c12', 'low': '#e74c3c'}\n",
    "color_list = [colors[tier] for tier in tier_counts.index]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(tier_counts.values, labels=[f\"{tier.title()}\\n({count})\" for tier, count in tier_counts.items()],\n",
    "        colors=color_list, autopct='%1.1f%%', startangle=90,\n",
    "        textprops={'fontsize': 12, 'weight': 'bold'})\n",
    "plt.title('Confidence Tier Distribution', fontsize=14, weight='bold')\n",
    "plt.savefig(RESULTS_DIR / 'confidence_tiers.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Top Candidates for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export top 10 for experimental validation\n",
    "validation_list = df.head(10)[[\n",
    "    'rank', 'gene_name', 'protein_id', 'protein_class',\n",
    "    'overall_score', 'ipTM_score', 'interface_pLDDT_score',\n",
    "    'structural_confidence', 'biological_relevance',\n",
    "    'confidence_tier'\n",
    "]]\n",
    "\n",
    "validation_list.to_csv(RESULTS_DIR / 'top10_for_validation.csv', index=False)\n",
    "print(\"âœ“ Exported top 10 candidates to top10_for_validation.csv\")\n",
    "\n",
    "validation_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PIPELINE SUMMARY STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"Total Candidates: {len(df)}\")\n",
    "print()\n",
    "print(\"Confidence Tiers:\")\n",
    "print(f\"  High:   {(df['confidence_tier'] == 'high').sum()} ({(df['confidence_tier'] == 'high').sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"  Medium: {(df['confidence_tier'] == 'medium').sum()} ({(df['confidence_tier'] == 'medium').sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"  Low:    {(df['confidence_tier'] == 'low').sum()} ({(df['confidence_tier'] == 'low').sum()/len(df)*100:.1f}%)\")\n",
    "print()\n",
    "print(\"ipTM Score Ranges:\")\n",
    "print(f\"  > 0.8 (High):   {(df['ipTM_score'] > 0.8).sum()}\")\n",
    "print(f\"  0.6-0.8 (Med):  {((df['ipTM_score'] >= 0.6) & (df['ipTM_score'] <= 0.8)).sum()}\")\n",
    "print(f\"  < 0.6 (Low):    {(df['ipTM_score'] < 0.6).sum()}\")\n",
    "print()\n",
    "print(\"Overall Score Statistics:\")\n",
    "print(f\"  Mean:   {df['overall_score'].mean():.3f}\")\n",
    "print(f\"  Median: {df['overall_score'].median():.3f}\")\n",
    "print(f\"  Std:    {df['overall_score'].std():.3f}\")\n",
    "print(f\"  Max:    {df['overall_score'].max():.3f} ({df.loc[df['overall_score'].idxmax(), 'gene_name']})\")\n",
    "print()\n",
    "print(\"Recommended for Experimental Validation:\")\n",
    "print(f\"  Top 3-5 candidates with ipTM > 0.8\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
