{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexed Random Access: FAI and TBI\n",
    "\n",
    "This notebook demonstrates how to use **FAI (FASTA Index)** and **TBI (Tabix Index)** for efficient random access to genomic data.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **FAI (FASTA Index)**\n",
    "   - Build and load FASTA indices\n",
    "   - Fetch entire sequences or specific regions\n",
    "   - Use cases: gene extraction, reference lookups\n",
    "\n",
    "2. **TBI (Tabix Index)**\n",
    "   - Load tabix indices for VCF/BED/GFF3 files\n",
    "   - Query specific genomic regions\n",
    "   - Use cases: variant calling, peak overlaps\n",
    "\n",
    "3. **Performance Benefits**\n",
    "   - 100-1000× speedup vs sequential scanning\n",
    "   - Constant memory usage\n",
    "   - Essential for large-scale genomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biometal\n",
    "import tempfile\n",
    "import os\n",
    "import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: FAI - FASTA Indexing\n",
    "\n",
    "FAI enables O(1) random access to any sequence in a FASTA file without loading the entire file into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample FASTA file\n",
    "fasta_data = \"\"\"##chr1 Human chromosome 1\n",
    "ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\n",
    "TGCATGCATGCATGCATGCATGCATGCATGCATGCATGCATGCATGCATGCATGCATGCA\n",
    ">chr2 Human chromosome 2\n",
    "GGGGCCCCAAAATTTTGGGGCCCCAAAATTTTGGGGCCCCAAAATTTTGGGGCCCCAAAA\n",
    "TTTTGGGGCCCCAAAATTTTGGGGCCCCAAAATTTTGGGGCCCCAAAATTTTGGGGCCCC\n",
    ">chrM Mitochondrial DNA\n",
    "ATCGATCGATCGATCGATCGATCG\n",
    "\"\"\"\n",
    "\n",
    "# Write to temporary file\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.fa', delete=False) as f:\n",
    "    fasta_path = f.name\n",
    "    f.write(fasta_data)\n",
    "\n",
    "print(f\"Created FASTA file: {fasta_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Build the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build FAI index from FASTA file\n",
    "fai_index = biometal.FaiIndex.build(fasta_path)\n",
    "print(f\"Built index with {len(fai_index)} sequences\")\n",
    "print(f\"Sequence names: {fai_index.sequence_names()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save and Load Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index to file\n",
    "fai_path = fasta_path + \".fai\"\n",
    "fai_index.write(fai_path)\n",
    "print(f\"Saved index to: {fai_path}\")\n",
    "\n",
    "# Load index from file (fast: <1ms)\n",
    "loaded_index = biometal.FaiIndex.from_path(fai_path)\n",
    "print(f\"Loaded index: {len(loaded_index)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Query Sequence Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info for each sequence\n",
    "for seq_name in loaded_index.sequence_names():\n",
    "    info = loaded_index.get_info(seq_name)\n",
    "    print(f\"{seq_name}:\")\n",
    "    print(f\"  Length: {info['length']} bp\")\n",
    "    print(f\"  Offset: {info['offset']} bytes\")\n",
    "    print(f\"  Line bases: {info['line_bases']}\")\n",
    "    print(f\"  Line width: {info['line_width']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fetch Entire Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch entire sequences\n",
    "chr1 = loaded_index.fetch(\"chr1\", fasta_path)\n",
    "print(f\"chr1: {len(chr1)} bp\")\n",
    "print(f\"First 60 bp: {chr1[:60]}\")\n",
    "\n",
    "chrM = loaded_index.fetch(\"chrM\", fasta_path)\n",
    "print(f\"\\nchrM: {len(chrM)} bp\")\n",
    "print(f\"Full sequence: {chrM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Fetch Specific Regions\n",
    "\n",
    "This is where FAI really shines - extracting small regions without reading the entire sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch region [0, 20) from chr1\n",
    "region1 = loaded_index.fetch_region(\"chr1\", 0, 20, fasta_path)\n",
    "print(f\"chr1:0-20 = {region1}\")\n",
    "\n",
    "# Fetch region [60, 80) - crosses line boundary\n",
    "region2 = loaded_index.fetch_region(\"chr1\", 60, 80, fasta_path)\n",
    "print(f\"chr1:60-80 = {region2}\")\n",
    "\n",
    "# Fetch middle of chr2\n",
    "region3 = loaded_index.fetch_region(\"chr2\", 30, 50, fasta_path)\n",
    "print(f\"chr2:30-50 = {region3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case: Extract Gene Sequence and Calculate GC Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate extracting a gene at chr1:25-55\n",
    "gene_seq = loaded_index.fetch_region(\"chr1\", 25, 55, fasta_path)\n",
    "print(f\"Gene sequence: {gene_seq}\")\n",
    "print(f\"Length: {len(gene_seq)} bp\")\n",
    "\n",
    "# Calculate GC content\n",
    "gc_count = sum(1 for base in gene_seq if base in 'GC')\n",
    "gc_percent = (gc_count / len(gene_seq)) * 100\n",
    "print(f\"GC content: {gc_percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: TBI - Tabix Indexing\n",
    "\n",
    "TBI enables efficient region queries on sorted, BGZF-compressed tab-delimited files (VCF, BED, GFF3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vcf_tbi():\n",
    "    \"\"\"Create a minimal VCF TBI index for demonstration\"\"\"\n",
    "    data = bytearray()\n",
    "    \n",
    "    # Magic \"TBI\\1\"\n",
    "    data.extend(b\"TBI\\x01\")\n",
    "    \n",
    "    # n_ref = 2 (chr1, chr2)\n",
    "    data.extend(struct.pack('<i', 2))\n",
    "    \n",
    "    # format = 2 (VCF)\n",
    "    data.extend(struct.pack('<i', 2))\n",
    "    \n",
    "    # col_seq = 0, col_beg = 1, col_end = 0\n",
    "    data.extend(struct.pack('<i', 0))  # CHROM\n",
    "    data.extend(struct.pack('<i', 1))  # POS\n",
    "    data.extend(struct.pack('<i', 0))  # END (same as POS for VCF)\n",
    "    \n",
    "    # meta = '#', skip = 0\n",
    "    data.extend(struct.pack('<i', ord('#')))\n",
    "    data.extend(struct.pack('<i', 0))\n",
    "    \n",
    "    # l_nm = 10 (\"chr1\\0chr2\\0\")\n",
    "    data.extend(struct.pack('<i', 10))\n",
    "    data.extend(b\"chr1\\0chr2\\0\")\n",
    "    \n",
    "    # Index for chr1: 2 bins\n",
    "    data.extend(struct.pack('<i', 2))  # n_bin\n",
    "    \n",
    "    # Bin 0 (entire chromosome)\n",
    "    data.extend(struct.pack('<I', 0))  # bin_id\n",
    "    data.extend(struct.pack('<i', 1))  # n_chunk\n",
    "    data.extend(struct.pack('<Q', 0x100000))  # chunk start\n",
    "    data.extend(struct.pack('<Q', 0x200000))  # chunk end\n",
    "    \n",
    "    # Bin 4681 (specific region)\n",
    "    data.extend(struct.pack('<I', 4681))\n",
    "    data.extend(struct.pack('<i', 1))\n",
    "    data.extend(struct.pack('<Q', 0x150000))\n",
    "    data.extend(struct.pack('<Q', 0x180000))\n",
    "    \n",
    "    # Linear index: 3 intervals\n",
    "    data.extend(struct.pack('<i', 3))\n",
    "    data.extend(struct.pack('<Q', 0x100000))\n",
    "    data.extend(struct.pack('<Q', 0x120000))\n",
    "    data.extend(struct.pack('<Q', 0x150000))\n",
    "    \n",
    "    # Index for chr2: 1 bin\n",
    "    data.extend(struct.pack('<i', 1))\n",
    "    data.extend(struct.pack('<I', 0))\n",
    "    data.extend(struct.pack('<i', 1))\n",
    "    data.extend(struct.pack('<Q', 0x300000))\n",
    "    data.extend(struct.pack('<Q', 0x400000))\n",
    "    \n",
    "    # Linear index\n",
    "    data.extend(struct.pack('<i', 2))\n",
    "    data.extend(struct.pack('<Q', 0x300000))\n",
    "    data.extend(struct.pack('<Q', 0x350000))\n",
    "    \n",
    "    return bytes(data)\n",
    "\n",
    "# Create TBI file\n",
    "tbi_data = create_vcf_tbi()\n",
    "with tempfile.NamedTemporaryFile(mode='wb', suffix='.vcf.gz.tbi', delete=False) as f:\n",
    "    tbi_path = f.name\n",
    "    f.write(tbi_data)\n",
    "\n",
    "print(f\"Created TBI file: {tbi_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load TBI Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TBI index\n",
    "tbi_index = biometal.TbiIndex.from_path(tbi_path)\n",
    "print(f\"Loaded TBI index\")\n",
    "print(f\"Format: {tbi_index.format()}\")\n",
    "print(f\"References: {tbi_index.references()}\")\n",
    "print(f\"Number of references: {len(tbi_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Query Index Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata\n",
    "print(\"Index metadata:\")\n",
    "print(f\"  CHROM column: {tbi_index.col_seq()}\")\n",
    "print(f\"  POS column: {tbi_index.col_beg()}\")\n",
    "print(f\"  END column: {tbi_index.col_end()}\")\n",
    "print(f\"  Comment char: '{tbi_index.meta_char()}'\")\n",
    "print(f\"  Skip lines: {tbi_index.skip_lines()}\")\n",
    "\n",
    "# Check reference info\n",
    "for ref_name in tbi_index.references():\n",
    "    info = tbi_index.get_info(ref_name)\n",
    "    print(f\"\\n{ref_name}:\")\n",
    "    print(f\"  Bins: {info['n_bins']}\")\n",
    "    print(f\"  Intervals: {info['n_intervals']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Query Genomic Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query chr1:0-100000\n",
    "print(\"Query: chr1:0-100000\")\n",
    "chunks = tbi_index.query(\"chr1\", 0, 100000)\n",
    "print(f\"Found {len(chunks)} chunks:\")\n",
    "for i, (start, end) in enumerate(chunks):\n",
    "    print(f\"  Chunk {i}: 0x{start:016x} - 0x{end:016x}\")\n",
    "    print(f\"           (compressed: 0x{start >> 16:x}, uncompressed: 0x{start & 0xFFFF:x})\")\n",
    "\n",
    "# Query chr2:0-50000\n",
    "print(\"\\nQuery: chr2:0-50000\")\n",
    "chunks = tbi_index.query(\"chr2\", 0, 50000)\n",
    "print(f\"Found {len(chunks)} chunks:\")\n",
    "for i, (start, end) in enumerate(chunks):\n",
    "    print(f\"  Chunk {i}: 0x{start:016x} - 0x{end:016x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Check Reference Existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if references exist\n",
    "print(f\"chr1 exists: {tbi_index.contains('chr1')}\")\n",
    "print(f\"chr2 exists: {tbi_index.contains('chr2')}\")\n",
    "print(f\"chr99 exists: {tbi_index.contains('chr99')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error handling\n",
    "try:\n",
    "    tbi_index.query(\"chr99\", 0, 100000)\n",
    "    print(\"ERROR: Should have raised exception\")\n",
    "except ValueError as e:\n",
    "    print(f\"✓ Correctly rejected chr99: {e}\")\n",
    "\n",
    "try:\n",
    "    tbi_index.query(\"chr1\", 100000, 50000)\n",
    "    print(\"ERROR: Should have raised exception\")\n",
    "except ValueError as e:\n",
    "    print(f\"✓ Correctly rejected invalid range: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Targeted Variant Analysis\n",
    "\n",
    "Practical workflow for extracting variants in a specific gene region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: Find variants in BRCA2 gene region\n",
    "gene_name = \"BRCA2\"\n",
    "chromosome = \"chr1\"  # Demo\n",
    "gene_start = 32_889_000\n",
    "gene_end = 32_974_000\n",
    "\n",
    "print(f\"Analyzing {gene_name} region: {chromosome}:{gene_start:,}-{gene_end:,}\")\n",
    "print()\n",
    "\n",
    "# Step 1: Query TBI index\n",
    "print(\"Step 1: Query TBI index for relevant file chunks\")\n",
    "chunks = tbi_index.query(chromosome, gene_start, gene_end)\n",
    "print(f\"→ Found {len(chunks)} chunks to read\")\n",
    "print()\n",
    "\n",
    "# Step 2: Show file offsets\n",
    "print(\"Step 2: File offsets to seek to\")\n",
    "for i, (start, end) in enumerate(chunks):\n",
    "    compressed_offset = start >> 16\n",
    "    uncompressed_offset = start & 0xFFFF\n",
    "    print(f\"  Chunk {i}:\")\n",
    "    print(f\"    Virtual offset: 0x{start:016x}\")\n",
    "    print(f\"    Seek to byte: {compressed_offset}\")\n",
    "    print(f\"    Uncompressed offset: {uncompressed_offset}\")\n",
    "print()\n",
    "\n",
    "# Step 3: Workflow explanation\n",
    "print(\"Step 3: Complete workflow\")\n",
    "print(\"1. Open BGZF-compressed VCF file\")\n",
    "print(\"2. Seek to first chunk's compressed offset\")\n",
    "print(\"3. Stream VCF records using biometal.VcfStream\")\n",
    "print(f\"4. Filter records where {gene_start} <= POS < {gene_end}\")\n",
    "print(\"5. Process variants (parse genotypes, calculate AF, etc.)\")\n",
    "print()\n",
    "\n",
    "print(\"Benefits:\")\n",
    "print(\"  • Skip reading entire VCF file\")\n",
    "print(\"  • Only decompress relevant BGZF blocks\")\n",
    "print(\"  • 100-1000× faster than full scan\")\n",
    "print(\"  • Constant memory usage (~5 MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Characteristics\n",
    "\n",
    "### FAI (FASTA Index)\n",
    "\n",
    "| Operation | Complexity | Typical Time |\n",
    "|-----------|------------|-------------|\n",
    "| Load index | O(n) sequences | <1 ms |\n",
    "| Sequence lookup | O(1) hash | <1 µs |\n",
    "| Region fetch | O(1) seek + O(m) read | 1-10 ms |\n",
    "| Memory | O(n) sequences | ~200 bytes/seq |\n",
    "\n",
    "### TBI (Tabix Index)\n",
    "\n",
    "| Operation | Complexity | Typical Time |\n",
    "|-----------|------------|-------------|\n",
    "| Load index | O(n) file size | 1-10 ms |\n",
    "| Region query | O(log n) bins | <1 ms |\n",
    "| Chunk count | Variable | 1-10 chunks |\n",
    "| Memory | O(n) references | 1-10 MB |\n",
    "| Speedup vs scan | Depends on region | 100-1000× |\n",
    "\n",
    "### When to Use Indexed Access\n",
    "\n",
    "✅ **Use FAI/TBI when:**\n",
    "- Querying specific regions (<10% of file)\n",
    "- Random access patterns\n",
    "- Memory-constrained environments\n",
    "- Interactive analysis\n",
    "\n",
    "❌ **Use streaming when:**\n",
    "- Processing entire file\n",
    "- Sequential access\n",
    "- Simple filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files\n",
    "import os\n",
    "os.unlink(fasta_path)\n",
    "os.unlink(fai_path)\n",
    "os.unlink(tbi_path)\n",
    "print(\"Cleaned up temporary files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **FAI (FASTA Index)**\n",
    "   - Build indices with `FaiIndex.build()`\n",
    "   - Fetch sequences with `fetch()` and regions with `fetch_region()`\n",
    "   - O(1) access to any sequence or region\n",
    "\n",
    "2. **TBI (Tabix Index)**\n",
    "   - Load indices with `TbiIndex.from_path()`\n",
    "   - Query regions with `query()` to get file chunks\n",
    "   - O(log n) region queries on compressed files\n",
    "\n",
    "3. **Performance**\n",
    "   - 100-1000× faster than sequential scanning\n",
    "   - Constant memory usage\n",
    "   - Essential for large-scale genomics\n",
    "\n",
    "4. **Use Cases**\n",
    "   - Gene extraction and analysis\n",
    "   - Targeted variant calling\n",
    "   - Peak overlap analysis\n",
    "   - Region-specific queries\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try with real genomic data\n",
    "- Combine with VCF/BED streaming parsers\n",
    "- Batch process multiple regions\n",
    "- Build production pipelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
